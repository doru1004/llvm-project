; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -mtriple=amdgcn-mesa-mesa3d -mcpu=gfx900 < %s | FileCheck -check-prefixes=GCN,GFX9 %s
; RUN: llc -mtriple=amdgcn-mesa-mesa3d -mcpu=gfx1010 -mattr=+wavefrontsize64 < %s | FileCheck -check-prefixes=GCN,GFX10 %s
; RUN: llc -mtriple=amdgcn-mesa-mesa3d -mcpu=gfx1100 -mattr=+wavefrontsize64 < %s | FileCheck -check-prefixes=GFX11 %s

; Test using saddr addressing mode of global_* flat atomic instructions.

define amdgpu_ps void @global_xchg_saddr_i32_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_xchg_saddr_i32_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_swap v0, v1, s[2:3]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_xchg_saddr_i32_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_swap v0, v1, s[2:3]
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_xchg_saddr_i32_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_swap_b32 v0, v1, s[2:3]
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %unused = atomicrmw xchg i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  ret void
}

; Maximum positive offset on gfx10
define amdgpu_ps void @global_xchg_saddr_i32_nortn_offset_2047(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_xchg_saddr_i32_nortn_offset_2047:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_swap v0, v1, s[2:3] offset:2047
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_xchg_saddr_i32_nortn_offset_2047:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_swap v0, v1, s[2:3] offset:2047
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_xchg_saddr_i32_nortn_offset_2047:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_swap_b32 v0, v1, s[2:3] offset:2047
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 2047
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %unused = atomicrmw xchg i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  ret void
}

; Maximum negative offset on gfx10
define amdgpu_ps void @global_xchg_saddr_i32_nortn_offset_neg2048(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_xchg_saddr_i32_nortn_offset_neg2048:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_swap v0, v1, s[2:3] offset:-2048
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_xchg_saddr_i32_nortn_offset_neg2048:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_swap v0, v1, s[2:3] offset:-2048
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_xchg_saddr_i32_nortn_offset_neg2048:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_swap_b32 v0, v1, s[2:3] offset:-2048
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -2048
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %unused = atomicrmw xchg i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  ret void
}

define amdgpu_ps float @global_xchg_saddr_i32_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_xchg_saddr_i32_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_swap v0, v0, v1, s[2:3] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_xchg_saddr_i32_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_swap v0, v0, v1, s[2:3] glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_xchg_saddr_i32_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_swap_b32 v0, v0, v1, s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %rtn = atomicrmw xchg i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @global_xchg_saddr_i32_rtn_2048(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_xchg_saddr_i32_rtn_2048:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_swap v0, v0, v1, s[2:3] offset:2048 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_xchg_saddr_i32_rtn_2048:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_add_co_u32 v0, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    v_add_co_u32 v2, vcc, 0x800, v0
; GFX10-NEXT:    v_add_co_ci_u32_e32 v3, vcc, 0, v3, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_swap v0, v[2:3], v1, off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_xchg_saddr_i32_rtn_2048:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_swap_b32 v0, v0, v1, s[2:3] offset:2048 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 2048
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %rtn = atomicrmw xchg i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @global_xchg_saddr_i32_rtn_neg2048(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_xchg_saddr_i32_rtn_neg2048:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_swap v0, v0, v1, s[2:3] offset:-2048 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_xchg_saddr_i32_rtn_neg2048:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_swap v0, v0, v1, s[2:3] offset:-2048 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_xchg_saddr_i32_rtn_neg2048:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_swap_b32 v0, v0, v1, s[2:3] offset:-2048 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -2048
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %rtn = atomicrmw xchg i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

; --------------------------------------------------------------------------------
; Uniformity edge cases
; --------------------------------------------------------------------------------

@ptr.in.lds = internal addrspace(3) global i8 addrspace(1)* undef

; Base pointer is uniform, but also in VGPRs
define amdgpu_ps float @global_xchg_saddr_uniform_ptr_in_vgprs_rtn(i32 %voffset, i32 %data) {
; GFX9-LABEL: global_xchg_saddr_uniform_ptr_in_vgprs_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v2, 0
; GFX9-NEXT:    ds_read_b64 v[2:3], v2
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    v_readfirstlane_b32 s0, v2
; GFX9-NEXT:    v_readfirstlane_b32 s1, v3
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    s_nop 3
; GFX9-NEXT:    global_atomic_swap v0, v0, v1, s[0:1] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_xchg_saddr_uniform_ptr_in_vgprs_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v2, 0
; GFX10-NEXT:    ds_read_b64 v[2:3], v2
; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10-NEXT:    v_readfirstlane_b32 s0, v2
; GFX10-NEXT:    v_readfirstlane_b32 s1, v3
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_swap v0, v0, v1, s[0:1] glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_xchg_saddr_uniform_ptr_in_vgprs_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    ds_load_b64 v[2:3], v2
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v2
; GFX11-NEXT:    v_readfirstlane_b32 s1, v3
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_swap_b32 v0, v0, v1, s[0:1] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %sbase = load i8 addrspace(1)*, i8 addrspace(1)* addrspace(3)* @ptr.in.lds
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %rtn = atomicrmw xchg i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

; Base pointer is uniform, but also in VGPRs, with imm offset
define amdgpu_ps float @global_xchg_saddr_uniform_ptr_in_vgprs_rtn_immoffset(i32 %voffset, i32 %data) {
; GFX9-LABEL: global_xchg_saddr_uniform_ptr_in_vgprs_rtn_immoffset:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v2, 0
; GFX9-NEXT:    ds_read_b64 v[2:3], v2
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    v_readfirstlane_b32 s0, v2
; GFX9-NEXT:    v_readfirstlane_b32 s1, v3
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    s_nop 3
; GFX9-NEXT:    global_atomic_swap v0, v0, v1, s[0:1] offset:42 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_xchg_saddr_uniform_ptr_in_vgprs_rtn_immoffset:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v2, 0
; GFX10-NEXT:    ds_read_b64 v[2:3], v2
; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10-NEXT:    v_readfirstlane_b32 s0, v2
; GFX10-NEXT:    v_readfirstlane_b32 s1, v3
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_swap v0, v0, v1, s[0:1] offset:42 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_xchg_saddr_uniform_ptr_in_vgprs_rtn_immoffset:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    ds_load_b64 v[2:3], v2
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v2
; GFX11-NEXT:    v_readfirstlane_b32 s1, v3
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_swap_b32 v0, v0, v1, s[0:1] offset:42 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %sbase = load i8 addrspace(1)*, i8 addrspace(1)* addrspace(3)* @ptr.in.lds
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 42
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %rtn = atomicrmw xchg i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

; Base pointer is uniform, but also in VGPRs
define amdgpu_ps void @global_xchg_saddr_uniform_ptr_in_vgprs_nortn(i32 %voffset, i32 %data) {
; GFX9-LABEL: global_xchg_saddr_uniform_ptr_in_vgprs_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v2, 0
; GFX9-NEXT:    ds_read_b64 v[2:3], v2
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    v_readfirstlane_b32 s0, v2
; GFX9-NEXT:    v_readfirstlane_b32 s1, v3
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    s_nop 3
; GFX9-NEXT:    global_atomic_swap v0, v1, s[0:1]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_xchg_saddr_uniform_ptr_in_vgprs_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v2, 0
; GFX10-NEXT:    ds_read_b64 v[2:3], v2
; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10-NEXT:    v_readfirstlane_b32 s0, v2
; GFX10-NEXT:    v_readfirstlane_b32 s1, v3
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_swap v0, v1, s[0:1]
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_xchg_saddr_uniform_ptr_in_vgprs_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    ds_load_b64 v[2:3], v2
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v2
; GFX11-NEXT:    v_readfirstlane_b32 s1, v3
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_swap_b32 v0, v1, s[0:1]
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %sbase = load i8 addrspace(1)*, i8 addrspace(1)* addrspace(3)* @ptr.in.lds
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %unused = atomicrmw xchg i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  ret void
}

; Base pointer is uniform, but also in VGPRs, with imm offset
define amdgpu_ps void @global_xchg_saddr_uniform_ptr_in_vgprs_nortn_immoffset(i32 %voffset, i32 %data) {
; GFX9-LABEL: global_xchg_saddr_uniform_ptr_in_vgprs_nortn_immoffset:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v2, 0
; GFX9-NEXT:    ds_read_b64 v[2:3], v2
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    v_readfirstlane_b32 s0, v2
; GFX9-NEXT:    v_readfirstlane_b32 s1, v3
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    s_nop 3
; GFX9-NEXT:    global_atomic_swap v0, v1, s[0:1] offset:42
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_xchg_saddr_uniform_ptr_in_vgprs_nortn_immoffset:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v2, 0
; GFX10-NEXT:    ds_read_b64 v[2:3], v2
; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10-NEXT:    v_readfirstlane_b32 s0, v2
; GFX10-NEXT:    v_readfirstlane_b32 s1, v3
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_swap v0, v1, s[0:1] offset:42
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_xchg_saddr_uniform_ptr_in_vgprs_nortn_immoffset:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, 0
; GFX11-NEXT:    ds_load_b64 v[2:3], v2
; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
; GFX11-NEXT:    v_readfirstlane_b32 s0, v2
; GFX11-NEXT:    v_readfirstlane_b32 s1, v3
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_swap_b32 v0, v1, s[0:1] offset:42
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %sbase = load i8 addrspace(1)*, i8 addrspace(1)* addrspace(3)* @ptr.in.lds
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 42
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %unused = atomicrmw xchg i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; All atomicrmw ops
; --------------------------------------------------------------------------------

; --------------------------------------------------------------------------------
; atomicrmw xchg
; --------------------------------------------------------------------------------

define amdgpu_ps <2 x float> @global_xchg_saddr_i64_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_xchg_saddr_i64_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_swap_x2 v[0:1], v0, v[1:2], s[2:3] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_xchg_saddr_i64_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_swap_x2 v[0:1], v0, v[1:2], s[2:3] glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_xchg_saddr_i64_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_swap_b64 v[0:1], v0, v[1:2], s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %rtn = atomicrmw xchg i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @global_xchg_saddr_i64_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_xchg_saddr_i64_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_swap_x2 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_xchg_saddr_i64_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_swap_x2 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_xchg_saddr_i64_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_swap_b64 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %rtn = atomicrmw xchg i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @global_xchg_saddr_i64_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_xchg_saddr_i64_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_swap_x2 v0, v[1:2], s[2:3]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_xchg_saddr_i64_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_swap_x2 v0, v[1:2], s[2:3]
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_xchg_saddr_i64_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_swap_b64 v0, v[1:2], s[2:3]
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %unused = atomicrmw xchg i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  ret void
}

define amdgpu_ps void @global_xchg_saddr_i64_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_xchg_saddr_i64_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_swap_x2 v0, v[1:2], s[2:3] offset:-128
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_xchg_saddr_i64_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_swap_x2 v0, v[1:2], s[2:3] offset:-128
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_xchg_saddr_i64_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_swap_b64 v0, v[1:2], s[2:3] offset:-128
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %unused = atomicrmw xchg i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw add
; --------------------------------------------------------------------------------

define amdgpu_ps float @global_add_saddr_i32_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_add_saddr_i32_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_add v0, v0, v1, s[2:3] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_add_saddr_i32_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_add v0, v0, v1, s[2:3] glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_add_saddr_i32_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_add_u32 v0, v0, v1, s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %rtn = atomicrmw add i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @global_add_saddr_i32_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_add_saddr_i32_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_add v0, v0, v1, s[2:3] offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_add_saddr_i32_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_add v0, v0, v1, s[2:3] offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_add_saddr_i32_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_add_u32 v0, v0, v1, s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %rtn = atomicrmw add i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @global_add_saddr_i32_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_add_saddr_i32_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_add v0, v1, s[2:3]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_add_saddr_i32_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_add v0, v1, s[2:3]
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_add_saddr_i32_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_add_u32 v0, v1, s[2:3]
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %unused = atomicrmw add i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  ret void
}

define amdgpu_ps void @global_add_saddr_i32_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_add_saddr_i32_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_add v0, v1, s[2:3] offset:-128
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_add_saddr_i32_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_add v0, v1, s[2:3] offset:-128
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_add_saddr_i32_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_add_u32 v0, v1, s[2:3] offset:-128
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %unused = atomicrmw add i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  ret void
}

define amdgpu_ps <2 x float> @global_add_saddr_i64_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_add_saddr_i64_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_add_x2 v[0:1], v0, v[1:2], s[2:3] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_add_saddr_i64_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_add_x2 v[0:1], v0, v[1:2], s[2:3] glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_add_saddr_i64_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_add_u64 v[0:1], v0, v[1:2], s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %rtn = atomicrmw add i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @global_add_saddr_i64_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_add_saddr_i64_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_add_x2 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_add_saddr_i64_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_add_x2 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_add_saddr_i64_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_add_u64 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %rtn = atomicrmw add i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @global_add_saddr_i64_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_add_saddr_i64_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_add_x2 v0, v[1:2], s[2:3]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_add_saddr_i64_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_add_x2 v0, v[1:2], s[2:3]
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_add_saddr_i64_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_add_u64 v0, v[1:2], s[2:3]
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %unused = atomicrmw add i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  ret void
}

define amdgpu_ps void @global_add_saddr_i64_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_add_saddr_i64_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_add_x2 v0, v[1:2], s[2:3] offset:-128
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_add_saddr_i64_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_add_x2 v0, v[1:2], s[2:3] offset:-128
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_add_saddr_i64_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_add_u64 v0, v[1:2], s[2:3] offset:-128
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %unused = atomicrmw add i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw sub
; --------------------------------------------------------------------------------

define amdgpu_ps float @global_sub_saddr_i32_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_sub_saddr_i32_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_sub v0, v0, v1, s[2:3] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_sub_saddr_i32_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_sub v0, v0, v1, s[2:3] glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_sub_saddr_i32_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_sub_u32 v0, v0, v1, s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %rtn = atomicrmw sub i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @global_sub_saddr_i32_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_sub_saddr_i32_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_sub v0, v0, v1, s[2:3] offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_sub_saddr_i32_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_sub v0, v0, v1, s[2:3] offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_sub_saddr_i32_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_sub_u32 v0, v0, v1, s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %rtn = atomicrmw sub i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @global_sub_saddr_i32_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_sub_saddr_i32_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_sub v0, v1, s[2:3]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_sub_saddr_i32_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_sub v0, v1, s[2:3]
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_sub_saddr_i32_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_sub_u32 v0, v1, s[2:3]
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %unused = atomicrmw sub i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  ret void
}

define amdgpu_ps void @global_sub_saddr_i32_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_sub_saddr_i32_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_sub v0, v1, s[2:3] offset:-128
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_sub_saddr_i32_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_sub v0, v1, s[2:3] offset:-128
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_sub_saddr_i32_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_sub_u32 v0, v1, s[2:3] offset:-128
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %unused = atomicrmw sub i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  ret void
}

define amdgpu_ps <2 x float> @global_sub_saddr_i64_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_sub_saddr_i64_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_sub_x2 v[0:1], v0, v[1:2], s[2:3] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_sub_saddr_i64_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_sub_x2 v[0:1], v0, v[1:2], s[2:3] glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_sub_saddr_i64_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_sub_u64 v[0:1], v0, v[1:2], s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %rtn = atomicrmw sub i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @global_sub_saddr_i64_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_sub_saddr_i64_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_sub_x2 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_sub_saddr_i64_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_sub_x2 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_sub_saddr_i64_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_sub_u64 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %rtn = atomicrmw sub i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @global_sub_saddr_i64_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_sub_saddr_i64_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_sub_x2 v0, v[1:2], s[2:3]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_sub_saddr_i64_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_sub_x2 v0, v[1:2], s[2:3]
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_sub_saddr_i64_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_sub_u64 v0, v[1:2], s[2:3]
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %unused = atomicrmw sub i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  ret void
}

define amdgpu_ps void @global_sub_saddr_i64_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_sub_saddr_i64_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_sub_x2 v0, v[1:2], s[2:3] offset:-128
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_sub_saddr_i64_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_sub_x2 v0, v[1:2], s[2:3] offset:-128
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_sub_saddr_i64_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_sub_u64 v0, v[1:2], s[2:3] offset:-128
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %unused = atomicrmw sub i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw and
; --------------------------------------------------------------------------------

define amdgpu_ps float @global_and_saddr_i32_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_and_saddr_i32_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_and v0, v0, v1, s[2:3] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_and_saddr_i32_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_and v0, v0, v1, s[2:3] glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_and_saddr_i32_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_and_b32 v0, v0, v1, s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %rtn = atomicrmw and i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @global_and_saddr_i32_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_and_saddr_i32_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_and v0, v0, v1, s[2:3] offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_and_saddr_i32_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_and v0, v0, v1, s[2:3] offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_and_saddr_i32_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_and_b32 v0, v0, v1, s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %rtn = atomicrmw and i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @global_and_saddr_i32_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_and_saddr_i32_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_and v0, v1, s[2:3]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_and_saddr_i32_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_and v0, v1, s[2:3]
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_and_saddr_i32_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_and_b32 v0, v1, s[2:3]
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %unused = atomicrmw and i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  ret void
}

define amdgpu_ps void @global_and_saddr_i32_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_and_saddr_i32_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_and v0, v1, s[2:3] offset:-128
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_and_saddr_i32_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_and v0, v1, s[2:3] offset:-128
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_and_saddr_i32_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_and_b32 v0, v1, s[2:3] offset:-128
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %unused = atomicrmw and i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  ret void
}

define amdgpu_ps <2 x float> @global_and_saddr_i64_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_and_saddr_i64_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_and_x2 v[0:1], v0, v[1:2], s[2:3] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_and_saddr_i64_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_and_x2 v[0:1], v0, v[1:2], s[2:3] glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_and_saddr_i64_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_and_b64 v[0:1], v0, v[1:2], s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %rtn = atomicrmw and i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @global_and_saddr_i64_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_and_saddr_i64_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_and_x2 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_and_saddr_i64_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_and_x2 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_and_saddr_i64_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_and_b64 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %rtn = atomicrmw and i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @global_and_saddr_i64_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_and_saddr_i64_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_and_x2 v0, v[1:2], s[2:3]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_and_saddr_i64_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_and_x2 v0, v[1:2], s[2:3]
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_and_saddr_i64_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_and_b64 v0, v[1:2], s[2:3]
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %unused = atomicrmw and i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  ret void
}

define amdgpu_ps void @global_and_saddr_i64_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_and_saddr_i64_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_and_x2 v0, v[1:2], s[2:3] offset:-128
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_and_saddr_i64_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_and_x2 v0, v[1:2], s[2:3] offset:-128
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_and_saddr_i64_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_and_b64 v0, v[1:2], s[2:3] offset:-128
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %unused = atomicrmw and i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw or
; --------------------------------------------------------------------------------

define amdgpu_ps float @global_or_saddr_i32_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_or_saddr_i32_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_or v0, v0, v1, s[2:3] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_or_saddr_i32_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_or v0, v0, v1, s[2:3] glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_or_saddr_i32_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_or_b32 v0, v0, v1, s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %rtn = atomicrmw or i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @global_or_saddr_i32_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_or_saddr_i32_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_or v0, v0, v1, s[2:3] offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_or_saddr_i32_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_or v0, v0, v1, s[2:3] offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_or_saddr_i32_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_or_b32 v0, v0, v1, s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %rtn = atomicrmw or i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @global_or_saddr_i32_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_or_saddr_i32_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_or v0, v1, s[2:3]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_or_saddr_i32_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_or v0, v1, s[2:3]
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_or_saddr_i32_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_or_b32 v0, v1, s[2:3]
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %unused = atomicrmw or i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  ret void
}

define amdgpu_ps void @global_or_saddr_i32_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_or_saddr_i32_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_or v0, v1, s[2:3] offset:-128
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_or_saddr_i32_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_or v0, v1, s[2:3] offset:-128
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_or_saddr_i32_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_or_b32 v0, v1, s[2:3] offset:-128
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %unused = atomicrmw or i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  ret void
}

define amdgpu_ps <2 x float> @global_or_saddr_i64_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_or_saddr_i64_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_or_x2 v[0:1], v0, v[1:2], s[2:3] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_or_saddr_i64_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_or_x2 v[0:1], v0, v[1:2], s[2:3] glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_or_saddr_i64_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_or_b64 v[0:1], v0, v[1:2], s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %rtn = atomicrmw or i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @global_or_saddr_i64_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_or_saddr_i64_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_or_x2 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_or_saddr_i64_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_or_x2 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_or_saddr_i64_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_or_b64 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %rtn = atomicrmw or i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @global_or_saddr_i64_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_or_saddr_i64_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_or_x2 v0, v[1:2], s[2:3]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_or_saddr_i64_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_or_x2 v0, v[1:2], s[2:3]
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_or_saddr_i64_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_or_b64 v0, v[1:2], s[2:3]
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %unused = atomicrmw or i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  ret void
}

define amdgpu_ps void @global_or_saddr_i64_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_or_saddr_i64_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_or_x2 v0, v[1:2], s[2:3] offset:-128
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_or_saddr_i64_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_or_x2 v0, v[1:2], s[2:3] offset:-128
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_or_saddr_i64_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_or_b64 v0, v[1:2], s[2:3] offset:-128
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %unused = atomicrmw or i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw xor
; --------------------------------------------------------------------------------

define amdgpu_ps float @global_xor_saddr_i32_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_xor_saddr_i32_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_xor v0, v0, v1, s[2:3] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_xor_saddr_i32_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_xor v0, v0, v1, s[2:3] glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_xor_saddr_i32_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_xor_b32 v0, v0, v1, s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %rtn = atomicrmw xor i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @global_xor_saddr_i32_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_xor_saddr_i32_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_xor v0, v0, v1, s[2:3] offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_xor_saddr_i32_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_xor v0, v0, v1, s[2:3] offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_xor_saddr_i32_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_xor_b32 v0, v0, v1, s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %rtn = atomicrmw xor i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @global_xor_saddr_i32_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_xor_saddr_i32_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_xor v0, v1, s[2:3]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_xor_saddr_i32_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_xor v0, v1, s[2:3]
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_xor_saddr_i32_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_xor_b32 v0, v1, s[2:3]
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %unused = atomicrmw xor i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  ret void
}

define amdgpu_ps void @global_xor_saddr_i32_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_xor_saddr_i32_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_xor v0, v1, s[2:3] offset:-128
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_xor_saddr_i32_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_xor v0, v1, s[2:3] offset:-128
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_xor_saddr_i32_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_xor_b32 v0, v1, s[2:3] offset:-128
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %unused = atomicrmw xor i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  ret void
}

define amdgpu_ps <2 x float> @global_xor_saddr_i64_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_xor_saddr_i64_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_xor_x2 v[0:1], v0, v[1:2], s[2:3] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_xor_saddr_i64_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_xor_x2 v[0:1], v0, v[1:2], s[2:3] glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_xor_saddr_i64_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_xor_b64 v[0:1], v0, v[1:2], s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %rtn = atomicrmw xor i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @global_xor_saddr_i64_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_xor_saddr_i64_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_xor_x2 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_xor_saddr_i64_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_xor_x2 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_xor_saddr_i64_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_xor_b64 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %rtn = atomicrmw xor i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @global_xor_saddr_i64_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_xor_saddr_i64_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_xor_x2 v0, v[1:2], s[2:3]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_xor_saddr_i64_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_xor_x2 v0, v[1:2], s[2:3]
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_xor_saddr_i64_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_xor_b64 v0, v[1:2], s[2:3]
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %unused = atomicrmw xor i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  ret void
}

define amdgpu_ps void @global_xor_saddr_i64_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_xor_saddr_i64_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_xor_x2 v0, v[1:2], s[2:3] offset:-128
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_xor_saddr_i64_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_xor_x2 v0, v[1:2], s[2:3] offset:-128
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_xor_saddr_i64_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_xor_b64 v0, v[1:2], s[2:3] offset:-128
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %unused = atomicrmw xor i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw max
; --------------------------------------------------------------------------------

define amdgpu_ps float @global_max_saddr_i32_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_max_saddr_i32_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v2, v0
; GFX9-NEXT:    global_load_dword v0, v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v2
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB54_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    v_max_i32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB54_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_max_saddr_i32_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v2, v0
; GFX10-NEXT:    global_load_dword v0, v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB54_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    v_max_i32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB54_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_max_saddr_i32_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, v0
; GFX11-NEXT:    global_load_b32 v0, v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB54_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_max_i32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB54_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %rtn = atomicrmw max i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @global_max_saddr_i32_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_max_saddr_i32_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v2, v0
; GFX9-NEXT:    global_load_dword v0, v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v2
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB55_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    v_max_i32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB55_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_max_saddr_i32_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v2, v0
; GFX10-NEXT:    global_load_dword v0, v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB55_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    v_max_i32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB55_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_max_saddr_i32_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, v0
; GFX11-NEXT:    global_load_b32 v0, v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB55_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_max_i32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB55_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %rtn = atomicrmw max i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @global_max_saddr_i32_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_max_saddr_i32_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dword v5, v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB56_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_max_i32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB56_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_max_saddr_i32_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dword v5, v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB56_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_max_i32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB56_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_max_saddr_i32_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b32 v5, v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB56_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_max_i32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB56_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %unused = atomicrmw max i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  ret void
}

define amdgpu_ps void @global_max_saddr_i32_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_max_saddr_i32_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dword v5, v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB57_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_max_i32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB57_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_max_saddr_i32_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dword v5, v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB57_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_max_i32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB57_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_max_saddr_i32_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b32 v5, v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB57_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_max_i32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB57_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %unused = atomicrmw max i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  ret void
}

define amdgpu_ps <2 x float> @global_max_saddr_i64_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_max_saddr_i64_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v6, s3
; GFX9-NEXT:    v_add_co_u32_e32 v5, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v6, vcc, 0, v6, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB58_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v10, v4
; GFX9-NEXT:    v_mov_b32_e32 v9, v3
; GFX9-NEXT:    v_cmp_gt_i64_e32 vcc, v[9:10], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB58_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v0, v3
; GFX9-NEXT:    v_mov_b32_e32 v1, v4
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_max_saddr_i64_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v6, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB58_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v10, v4
; GFX10-NEXT:    v_mov_b32_e32 v9, v3
; GFX10-NEXT:    v_cmp_gt_i64_e32 vcc, v[9:10], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB58_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    v_mov_b32_e32 v0, v3
; GFX10-NEXT:    v_mov_b32_e32 v1, v4
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_max_saddr_i64_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[3:4], v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v6, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB58_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v10, v4
; GFX11-NEXT:    v_mov_b32_e32 v9, v3
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_cmp_gt_i64_e32 vcc, v[9:10], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[5:6], v[7:10], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB58_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    v_mov_b32_e32 v0, v3
; GFX11-NEXT:    v_mov_b32_e32 v1, v4
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %rtn = atomicrmw max i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @global_max_saddr_i64_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_max_saddr_i64_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v6, s3
; GFX9-NEXT:    v_add_co_u32_e32 v5, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v6, vcc, 0, v6, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB59_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v10, v4
; GFX9-NEXT:    v_mov_b32_e32 v9, v3
; GFX9-NEXT:    v_cmp_gt_i64_e32 vcc, v[9:10], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB59_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v0, v3
; GFX9-NEXT:    v_mov_b32_e32 v1, v4
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_max_saddr_i64_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v6, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB59_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v10, v4
; GFX10-NEXT:    v_mov_b32_e32 v9, v3
; GFX10-NEXT:    v_cmp_gt_i64_e32 vcc, v[9:10], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB59_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    v_mov_b32_e32 v0, v3
; GFX10-NEXT:    v_mov_b32_e32 v1, v4
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_max_saddr_i64_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[3:4], v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v6, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB59_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v10, v4
; GFX11-NEXT:    v_mov_b32_e32 v9, v3
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_cmp_gt_i64_e32 vcc, v[9:10], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[5:6], v[7:10], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB59_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    v_mov_b32_e32 v0, v3
; GFX11-NEXT:    v_mov_b32_e32 v1, v4
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %rtn = atomicrmw max i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @global_max_saddr_i64_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_max_saddr_i64_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v7, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v8, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB60_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_cmp_gt_i64_e32 vcc, v[5:6], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX9-NEXT:    v_mov_b32_e32 v6, v4
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v3
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB60_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_max_saddr_i64_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v8, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB60_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_cmp_gt_i64_e32 vcc, v[5:6], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX10-NEXT:    v_mov_b32_e32 v6, v4
; GFX10-NEXT:    v_mov_b32_e32 v5, v3
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB60_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_max_saddr_i64_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[5:6], v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v8, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB60_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_cmp_gt_i64_e32 vcc, v[5:6], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[7:8], v[3:6], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX11-NEXT:    v_mov_b32_e32 v6, v4
; GFX11-NEXT:    v_mov_b32_e32 v5, v3
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB60_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %unused = atomicrmw max i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  ret void
}

define amdgpu_ps void @global_max_saddr_i64_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_max_saddr_i64_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v7, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v8, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB61_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_cmp_gt_i64_e32 vcc, v[5:6], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX9-NEXT:    v_mov_b32_e32 v6, v4
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v3
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB61_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_max_saddr_i64_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v8, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB61_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_cmp_gt_i64_e32 vcc, v[5:6], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX10-NEXT:    v_mov_b32_e32 v6, v4
; GFX10-NEXT:    v_mov_b32_e32 v5, v3
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB61_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_max_saddr_i64_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[5:6], v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v8, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB61_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_cmp_gt_i64_e32 vcc, v[5:6], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[7:8], v[3:6], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX11-NEXT:    v_mov_b32_e32 v6, v4
; GFX11-NEXT:    v_mov_b32_e32 v5, v3
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB61_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %unused = atomicrmw max i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw min
; --------------------------------------------------------------------------------

define amdgpu_ps float @global_min_saddr_i32_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_min_saddr_i32_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v2, v0
; GFX9-NEXT:    global_load_dword v0, v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v2
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB62_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    v_min_i32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB62_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_min_saddr_i32_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v2, v0
; GFX10-NEXT:    global_load_dword v0, v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB62_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    v_min_i32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB62_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_min_saddr_i32_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, v0
; GFX11-NEXT:    global_load_b32 v0, v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB62_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_min_i32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB62_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %rtn = atomicrmw min i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @global_min_saddr_i32_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_min_saddr_i32_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v2, v0
; GFX9-NEXT:    global_load_dword v0, v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v2
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB63_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    v_min_i32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB63_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_min_saddr_i32_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v2, v0
; GFX10-NEXT:    global_load_dword v0, v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB63_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    v_min_i32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB63_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_min_saddr_i32_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, v0
; GFX11-NEXT:    global_load_b32 v0, v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB63_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_min_i32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB63_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %rtn = atomicrmw min i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @global_min_saddr_i32_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_min_saddr_i32_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dword v5, v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB64_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_min_i32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB64_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_min_saddr_i32_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dword v5, v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB64_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_min_i32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB64_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_min_saddr_i32_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b32 v5, v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB64_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_min_i32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB64_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %unused = atomicrmw min i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  ret void
}

define amdgpu_ps void @global_min_saddr_i32_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_min_saddr_i32_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dword v5, v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB65_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_min_i32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB65_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_min_saddr_i32_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dword v5, v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB65_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_min_i32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB65_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_min_saddr_i32_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b32 v5, v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB65_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_min_i32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB65_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %unused = atomicrmw min i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  ret void
}

define amdgpu_ps <2 x float> @global_min_saddr_i64_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_min_saddr_i64_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v6, s3
; GFX9-NEXT:    v_add_co_u32_e32 v5, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v6, vcc, 0, v6, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB66_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v10, v4
; GFX9-NEXT:    v_mov_b32_e32 v9, v3
; GFX9-NEXT:    v_cmp_le_i64_e32 vcc, v[9:10], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB66_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v0, v3
; GFX9-NEXT:    v_mov_b32_e32 v1, v4
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_min_saddr_i64_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v6, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB66_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v10, v4
; GFX10-NEXT:    v_mov_b32_e32 v9, v3
; GFX10-NEXT:    v_cmp_le_i64_e32 vcc, v[9:10], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB66_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    v_mov_b32_e32 v0, v3
; GFX10-NEXT:    v_mov_b32_e32 v1, v4
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_min_saddr_i64_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[3:4], v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v6, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB66_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v10, v4
; GFX11-NEXT:    v_mov_b32_e32 v9, v3
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_cmp_le_i64_e32 vcc, v[9:10], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[5:6], v[7:10], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB66_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    v_mov_b32_e32 v0, v3
; GFX11-NEXT:    v_mov_b32_e32 v1, v4
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %rtn = atomicrmw min i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @global_min_saddr_i64_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_min_saddr_i64_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v6, s3
; GFX9-NEXT:    v_add_co_u32_e32 v5, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v6, vcc, 0, v6, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB67_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v10, v4
; GFX9-NEXT:    v_mov_b32_e32 v9, v3
; GFX9-NEXT:    v_cmp_le_i64_e32 vcc, v[9:10], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB67_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v0, v3
; GFX9-NEXT:    v_mov_b32_e32 v1, v4
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_min_saddr_i64_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v6, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB67_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v10, v4
; GFX10-NEXT:    v_mov_b32_e32 v9, v3
; GFX10-NEXT:    v_cmp_le_i64_e32 vcc, v[9:10], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB67_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    v_mov_b32_e32 v0, v3
; GFX10-NEXT:    v_mov_b32_e32 v1, v4
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_min_saddr_i64_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[3:4], v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v6, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB67_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v10, v4
; GFX11-NEXT:    v_mov_b32_e32 v9, v3
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_cmp_le_i64_e32 vcc, v[9:10], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[5:6], v[7:10], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB67_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    v_mov_b32_e32 v0, v3
; GFX11-NEXT:    v_mov_b32_e32 v1, v4
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %rtn = atomicrmw min i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @global_min_saddr_i64_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_min_saddr_i64_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v7, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v8, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB68_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_cmp_le_i64_e32 vcc, v[5:6], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX9-NEXT:    v_mov_b32_e32 v6, v4
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v3
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB68_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_min_saddr_i64_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v8, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB68_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_cmp_le_i64_e32 vcc, v[5:6], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX10-NEXT:    v_mov_b32_e32 v6, v4
; GFX10-NEXT:    v_mov_b32_e32 v5, v3
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB68_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_min_saddr_i64_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[5:6], v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v8, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB68_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_cmp_le_i64_e32 vcc, v[5:6], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[7:8], v[3:6], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX11-NEXT:    v_mov_b32_e32 v6, v4
; GFX11-NEXT:    v_mov_b32_e32 v5, v3
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB68_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %unused = atomicrmw min i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  ret void
}

define amdgpu_ps void @global_min_saddr_i64_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_min_saddr_i64_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v7, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v8, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB69_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_cmp_le_i64_e32 vcc, v[5:6], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX9-NEXT:    v_mov_b32_e32 v6, v4
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v3
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB69_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_min_saddr_i64_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v8, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB69_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_cmp_le_i64_e32 vcc, v[5:6], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX10-NEXT:    v_mov_b32_e32 v6, v4
; GFX10-NEXT:    v_mov_b32_e32 v5, v3
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB69_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_min_saddr_i64_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[5:6], v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v8, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB69_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_cmp_le_i64_e32 vcc, v[5:6], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[7:8], v[3:6], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX11-NEXT:    v_mov_b32_e32 v6, v4
; GFX11-NEXT:    v_mov_b32_e32 v5, v3
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB69_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %unused = atomicrmw min i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw umax
; --------------------------------------------------------------------------------

define amdgpu_ps float @global_umax_saddr_i32_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_umax_saddr_i32_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v2, v0
; GFX9-NEXT:    global_load_dword v0, v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v2
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB70_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    v_max_u32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB70_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_umax_saddr_i32_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v2, v0
; GFX10-NEXT:    global_load_dword v0, v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB70_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    v_max_u32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB70_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_umax_saddr_i32_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, v0
; GFX11-NEXT:    global_load_b32 v0, v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB70_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_max_u32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB70_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %rtn = atomicrmw umax i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @global_umax_saddr_i32_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_umax_saddr_i32_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v2, v0
; GFX9-NEXT:    global_load_dword v0, v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v2
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB71_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    v_max_u32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB71_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_umax_saddr_i32_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v2, v0
; GFX10-NEXT:    global_load_dword v0, v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB71_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    v_max_u32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB71_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_umax_saddr_i32_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, v0
; GFX11-NEXT:    global_load_b32 v0, v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB71_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_max_u32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB71_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %rtn = atomicrmw umax i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @global_umax_saddr_i32_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_umax_saddr_i32_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dword v5, v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB72_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_max_u32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB72_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_umax_saddr_i32_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dword v5, v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB72_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_max_u32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB72_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_umax_saddr_i32_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b32 v5, v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB72_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_max_u32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB72_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %unused = atomicrmw umax i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  ret void
}

define amdgpu_ps void @global_umax_saddr_i32_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_umax_saddr_i32_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dword v5, v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB73_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_max_u32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB73_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_umax_saddr_i32_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dword v5, v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB73_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_max_u32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB73_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_umax_saddr_i32_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b32 v5, v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB73_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_max_u32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB73_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %unused = atomicrmw umax i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  ret void
}

define amdgpu_ps <2 x float> @global_umax_saddr_i64_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_umax_saddr_i64_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v6, s3
; GFX9-NEXT:    v_add_co_u32_e32 v5, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v6, vcc, 0, v6, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB74_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v10, v4
; GFX9-NEXT:    v_mov_b32_e32 v9, v3
; GFX9-NEXT:    v_cmp_gt_u64_e32 vcc, v[9:10], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB74_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v0, v3
; GFX9-NEXT:    v_mov_b32_e32 v1, v4
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_umax_saddr_i64_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v6, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB74_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v10, v4
; GFX10-NEXT:    v_mov_b32_e32 v9, v3
; GFX10-NEXT:    v_cmp_gt_u64_e32 vcc, v[9:10], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB74_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    v_mov_b32_e32 v0, v3
; GFX10-NEXT:    v_mov_b32_e32 v1, v4
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_umax_saddr_i64_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[3:4], v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v6, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB74_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v10, v4
; GFX11-NEXT:    v_mov_b32_e32 v9, v3
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_cmp_gt_u64_e32 vcc, v[9:10], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[5:6], v[7:10], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB74_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    v_mov_b32_e32 v0, v3
; GFX11-NEXT:    v_mov_b32_e32 v1, v4
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %rtn = atomicrmw umax i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @global_umax_saddr_i64_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_umax_saddr_i64_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v6, s3
; GFX9-NEXT:    v_add_co_u32_e32 v5, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v6, vcc, 0, v6, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB75_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v10, v4
; GFX9-NEXT:    v_mov_b32_e32 v9, v3
; GFX9-NEXT:    v_cmp_gt_u64_e32 vcc, v[9:10], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB75_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v0, v3
; GFX9-NEXT:    v_mov_b32_e32 v1, v4
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_umax_saddr_i64_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v6, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB75_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v10, v4
; GFX10-NEXT:    v_mov_b32_e32 v9, v3
; GFX10-NEXT:    v_cmp_gt_u64_e32 vcc, v[9:10], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB75_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    v_mov_b32_e32 v0, v3
; GFX10-NEXT:    v_mov_b32_e32 v1, v4
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_umax_saddr_i64_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[3:4], v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v6, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB75_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v10, v4
; GFX11-NEXT:    v_mov_b32_e32 v9, v3
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_cmp_gt_u64_e32 vcc, v[9:10], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[5:6], v[7:10], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB75_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    v_mov_b32_e32 v0, v3
; GFX11-NEXT:    v_mov_b32_e32 v1, v4
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %rtn = atomicrmw umax i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @global_umax_saddr_i64_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_umax_saddr_i64_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v7, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v8, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB76_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_cmp_gt_u64_e32 vcc, v[5:6], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX9-NEXT:    v_mov_b32_e32 v6, v4
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v3
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB76_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_umax_saddr_i64_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v8, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB76_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_cmp_gt_u64_e32 vcc, v[5:6], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX10-NEXT:    v_mov_b32_e32 v6, v4
; GFX10-NEXT:    v_mov_b32_e32 v5, v3
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB76_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_umax_saddr_i64_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[5:6], v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v8, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB76_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_cmp_gt_u64_e32 vcc, v[5:6], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[7:8], v[3:6], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX11-NEXT:    v_mov_b32_e32 v6, v4
; GFX11-NEXT:    v_mov_b32_e32 v5, v3
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB76_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %unused = atomicrmw umax i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  ret void
}

define amdgpu_ps void @global_umax_saddr_i64_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_umax_saddr_i64_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v7, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v8, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB77_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_cmp_gt_u64_e32 vcc, v[5:6], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX9-NEXT:    v_mov_b32_e32 v6, v4
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v3
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB77_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_umax_saddr_i64_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v8, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB77_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_cmp_gt_u64_e32 vcc, v[5:6], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX10-NEXT:    v_mov_b32_e32 v6, v4
; GFX10-NEXT:    v_mov_b32_e32 v5, v3
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB77_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_umax_saddr_i64_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[5:6], v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v8, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB77_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_cmp_gt_u64_e32 vcc, v[5:6], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[7:8], v[3:6], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX11-NEXT:    v_mov_b32_e32 v6, v4
; GFX11-NEXT:    v_mov_b32_e32 v5, v3
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB77_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %unused = atomicrmw umax i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; atomicrmw umin
; --------------------------------------------------------------------------------

define amdgpu_ps float @global_umin_saddr_i32_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_umin_saddr_i32_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v2, v0
; GFX9-NEXT:    global_load_dword v0, v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v2
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB78_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    v_min_u32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB78_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_umin_saddr_i32_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v2, v0
; GFX10-NEXT:    global_load_dword v0, v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB78_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    v_min_u32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB78_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_umin_saddr_i32_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, v0
; GFX11-NEXT:    global_load_b32 v0, v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB78_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_min_u32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB78_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %rtn = atomicrmw umin i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @global_umin_saddr_i32_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_umin_saddr_i32_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v2, v0
; GFX9-NEXT:    global_load_dword v0, v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v2
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB79_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    v_min_u32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB79_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_umin_saddr_i32_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v2, v0
; GFX10-NEXT:    global_load_dword v0, v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB79_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    v_min_u32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB79_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_umin_saddr_i32_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v2, v0
; GFX11-NEXT:    global_load_b32 v0, v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v2
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB79_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_min_u32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB79_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %rtn = atomicrmw umin i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @global_umin_saddr_i32_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_umin_saddr_i32_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dword v5, v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB80_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_min_u32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB80_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_umin_saddr_i32_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dword v5, v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB80_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_min_u32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB80_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_umin_saddr_i32_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b32 v5, v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB80_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_min_u32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB80_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %unused = atomicrmw umin i32 addrspace(1)* %cast.gep0, i32 %data seq_cst
  ret void
}

define amdgpu_ps void @global_umin_saddr_i32_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GFX9-LABEL: global_umin_saddr_i32_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dword v5, v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v2, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v3, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB81_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_min_u32_e32 v4, v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v0
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB81_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_umin_saddr_i32_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dword v5, v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v3, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB81_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_min_u32_e32 v4, v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], v[4:5], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX10-NEXT:    v_mov_b32_e32 v5, v0
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB81_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_umin_saddr_i32_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b32 v5, v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v2, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v3, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB81_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_min_u32_e32 v4, v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], v[4:5], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u32_e32 vcc, v0, v5
; GFX11-NEXT:    v_mov_b32_e32 v5, v0
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB81_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %unused = atomicrmw umin i32 addrspace(1)* %cast.gep1, i32 %data seq_cst
  ret void
}

define amdgpu_ps <2 x float> @global_umin_saddr_i64_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_umin_saddr_i64_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v6, s3
; GFX9-NEXT:    v_add_co_u32_e32 v5, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v6, vcc, 0, v6, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB82_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v10, v4
; GFX9-NEXT:    v_mov_b32_e32 v9, v3
; GFX9-NEXT:    v_cmp_le_u64_e32 vcc, v[9:10], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB82_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v0, v3
; GFX9-NEXT:    v_mov_b32_e32 v1, v4
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_umin_saddr_i64_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v6, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB82_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v10, v4
; GFX10-NEXT:    v_mov_b32_e32 v9, v3
; GFX10-NEXT:    v_cmp_le_u64_e32 vcc, v[9:10], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB82_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    v_mov_b32_e32 v0, v3
; GFX10-NEXT:    v_mov_b32_e32 v1, v4
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_umin_saddr_i64_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[3:4], v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v6, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB82_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v10, v4
; GFX11-NEXT:    v_mov_b32_e32 v9, v3
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_cmp_le_u64_e32 vcc, v[9:10], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[5:6], v[7:10], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB82_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    v_mov_b32_e32 v0, v3
; GFX11-NEXT:    v_mov_b32_e32 v1, v4
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %rtn = atomicrmw umin i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @global_umin_saddr_i64_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_umin_saddr_i64_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v6, s3
; GFX9-NEXT:    v_add_co_u32_e32 v5, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v6, vcc, 0, v6, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB83_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_mov_b32_e32 v10, v4
; GFX9-NEXT:    v_mov_b32_e32 v9, v3
; GFX9-NEXT:    v_cmp_le_u64_e32 vcc, v[9:10], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB83_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v0, v3
; GFX9-NEXT:    v_mov_b32_e32 v1, v4
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_umin_saddr_i64_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[3:4], v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v6, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB83_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_mov_b32_e32 v10, v4
; GFX10-NEXT:    v_mov_b32_e32 v9, v3
; GFX10-NEXT:    v_cmp_le_u64_e32 vcc, v[9:10], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[5:6], v[7:10], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB83_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX10-NEXT:    v_mov_b32_e32 v0, v3
; GFX10-NEXT:    v_mov_b32_e32 v1, v4
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_umin_saddr_i64_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[3:4], v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v5, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v6, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB83_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_mov_b32_e32 v10, v4
; GFX11-NEXT:    v_mov_b32_e32 v9, v3
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_cmp_le_u64_e32 vcc, v[9:10], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v8, v2, v10, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v7, v1, v9, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[5:6], v[7:10], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[9:10]
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB83_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_or_b64 exec, exec, s[0:1]
; GFX11-NEXT:    v_mov_b32_e32 v0, v3
; GFX11-NEXT:    v_mov_b32_e32 v1, v4
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %rtn = atomicrmw umin i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @global_umin_saddr_i64_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_umin_saddr_i64_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3]
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v7, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v8, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB84_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_cmp_le_u64_e32 vcc, v[5:6], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX9-NEXT:    v_mov_b32_e32 v6, v4
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v3
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB84_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_umin_saddr_i64_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3]
; GFX10-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v8, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB84_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_cmp_le_u64_e32 vcc, v[5:6], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX10-NEXT:    v_mov_b32_e32 v6, v4
; GFX10-NEXT:    v_mov_b32_e32 v5, v3
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB84_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_umin_saddr_i64_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[5:6], v0, s[2:3]
; GFX11-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v8, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB84_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_cmp_le_u64_e32 vcc, v[5:6], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[7:8], v[3:6], off glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX11-NEXT:    v_mov_b32_e32 v6, v4
; GFX11-NEXT:    v_mov_b32_e32 v5, v3
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB84_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %unused = atomicrmw umin i64 addrspace(1)* %cast.gep0, i64 %data seq_cst
  ret void
}

define amdgpu_ps void @global_umin_saddr_i64_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GFX9-LABEL: global_umin_saddr_i64_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3] offset:-128
; GFX9-NEXT:    v_mov_b32_e32 v3, s3
; GFX9-NEXT:    v_add_co_u32_e32 v7, vcc, s2, v0
; GFX9-NEXT:    v_addc_co_u32_e32 v8, vcc, 0, v3, vcc
; GFX9-NEXT:    s_mov_b64 s[0:1], 0
; GFX9-NEXT:  .LBB85_1: ; %atomicrmw.start
; GFX9-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_cmp_le_u64_e32 vcc, v[5:6], v[1:2]
; GFX9-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX9-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX9-NEXT:    v_mov_b32_e32 v6, v4
; GFX9-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX9-NEXT:    v_mov_b32_e32 v5, v3
; GFX9-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX9-NEXT:    s_cbranch_execnz .LBB85_1
; GFX9-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_umin_saddr_i64_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    global_load_dwordx2 v[5:6], v0, s[2:3] offset:-128
; GFX10-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX10-NEXT:    v_add_co_ci_u32_e64 v8, s[0:1], s3, 0, s[0:1]
; GFX10-NEXT:    s_mov_b64 s[0:1], 0
; GFX10-NEXT:  .LBB85_1: ; %atomicrmw.start
; GFX10-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    v_cmp_le_u64_e32 vcc, v[5:6], v[1:2]
; GFX10-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX10-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[3:4], v[7:8], v[3:6], off offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX10-NEXT:    v_mov_b32_e32 v6, v4
; GFX10-NEXT:    v_mov_b32_e32 v5, v3
; GFX10-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX10-NEXT:    s_andn2_b64 exec, exec, s[0:1]
; GFX10-NEXT:    s_cbranch_execnz .LBB85_1
; GFX10-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_umin_saddr_i64_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_load_b64 v[5:6], v0, s[2:3] offset:-128
; GFX11-NEXT:    v_add_co_u32 v7, s[0:1], s2, v0
; GFX11-NEXT:    s_delay_alu instid0(VALU_DEP_1)
; GFX11-NEXT:    v_add_co_ci_u32_e64 v8, null, s3, 0, s[0:1]
; GFX11-NEXT:    s_mov_b64 s[0:1], 0
; GFX11-NEXT:    s_waitcnt_depctr 0xfffe
; GFX11-NEXT:  .LBB85_1: ; %atomicrmw.start
; GFX11-NEXT:    ; =>This Inner Loop Header: Depth=1
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    v_cmp_le_u64_e32 vcc, v[5:6], v[1:2]
; GFX11-NEXT:    v_cndmask_b32_e32 v4, v2, v6, vcc
; GFX11-NEXT:    v_cndmask_b32_e32 v3, v1, v5, vcc
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[3:4], v[7:8], v[3:6], off offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    v_cmp_eq_u64_e32 vcc, v[3:4], v[5:6]
; GFX11-NEXT:    v_mov_b32_e32 v6, v4
; GFX11-NEXT:    v_mov_b32_e32 v5, v3
; GFX11-NEXT:    s_or_b64 s[0:1], vcc, s[0:1]
; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
; GFX11-NEXT:    s_and_not1_b64 exec, exec, s[0:1]
; GFX11-NEXT:    s_cbranch_execnz .LBB85_1
; GFX11-NEXT:  ; %bb.2: ; %atomicrmw.end
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %unused = atomicrmw umin i64 addrspace(1)* %cast.gep1, i64 %data seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; cmpxchg
; --------------------------------------------------------------------------------

define amdgpu_ps float @global_cmpxchg_saddr_i32_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %cmp, i32 %data) {
; GFX9-LABEL: global_cmpxchg_saddr_i32_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v3, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v0, v[2:3], s[2:3] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_cmpxchg_saddr_i32_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v3, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v0, v[2:3], s[2:3] glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_cmpxchg_saddr_i32_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v3, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v0, v[2:3], s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %cmpxchg = cmpxchg i32 addrspace(1)* %cast.gep0, i32 %cmp, i32 %data seq_cst seq_cst
  %rtn = extractvalue { i32, i1 } %cmpxchg, 0
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @global_cmpxchg_saddr_i32_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %cmp, i32 %data) {
; GFX9-LABEL: global_cmpxchg_saddr_i32_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v3, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v0, v[2:3], s[2:3] offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_cmpxchg_saddr_i32_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v3, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v0, v[2:3], s[2:3] offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_cmpxchg_saddr_i32_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v3, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v0, v[2:3], s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %cmpxchg = cmpxchg i32 addrspace(1)* %cast.gep1, i32 %cmp, i32 %data seq_cst seq_cst
  %rtn = extractvalue { i32, i1 } %cmpxchg, 0
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @global_cmpxchg_saddr_i32_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %cmp, i32 %data) {
; GFX9-LABEL: global_cmpxchg_saddr_i32_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v3, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], s[2:3]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_cmpxchg_saddr_i32_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v3, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], s[2:3]
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_cmpxchg_saddr_i32_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v3, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], s[2:3]
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %unused = cmpxchg i32 addrspace(1)* %cast.gep0, i32 %cmp, i32 %data seq_cst seq_cst
  ret void
}

define amdgpu_ps void @global_cmpxchg_saddr_i32_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %cmp, i32 %data) {
; GFX9-LABEL: global_cmpxchg_saddr_i32_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v3, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap v0, v[2:3], s[2:3] offset:-128
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_cmpxchg_saddr_i32_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v3, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap v0, v[2:3], s[2:3] offset:-128
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_cmpxchg_saddr_i32_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v3, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b32 v0, v[2:3], s[2:3] offset:-128
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %unused = cmpxchg i32 addrspace(1)* %cast.gep1, i32 %cmp, i32 %data seq_cst seq_cst
  ret void
}

define amdgpu_ps <2 x float> @global_cmpxchg_saddr_i64_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %cmp, i64 %data) {
; GFX9-LABEL: global_cmpxchg_saddr_i64_rtn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v6, v2
; GFX9-NEXT:    v_mov_b32_e32 v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[0:1], v0, v[3:6], s[2:3] glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_cmpxchg_saddr_i64_rtn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v6, v2
; GFX10-NEXT:    v_mov_b32_e32 v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[0:1], v0, v[3:6], s[2:3] glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_cmpxchg_saddr_i64_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v6, v2
; GFX11-NEXT:    v_mov_b32_e32 v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[0:1], v0, v[3:6], s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %cmpxchg = cmpxchg i64 addrspace(1)* %cast.gep0, i64 %cmp, i64 %data seq_cst seq_cst
  %rtn = extractvalue { i64, i1 } %cmpxchg, 0
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @global_cmpxchg_saddr_i64_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %cmp, i64 %data) {
; GFX9-LABEL: global_cmpxchg_saddr_i64_rtn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v6, v2
; GFX9-NEXT:    v_mov_b32_e32 v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v[0:1], v0, v[3:6], s[2:3] offset:-128 glc
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    ; return to shader part epilog
;
; GFX10-LABEL: global_cmpxchg_saddr_i64_rtn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v6, v2
; GFX10-NEXT:    v_mov_b32_e32 v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v[0:1], v0, v[3:6], s[2:3] offset:-128 glc
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_cmpxchg_saddr_i64_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v6, v2
; GFX11-NEXT:    v_mov_b32_e32 v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v[0:1], v0, v[3:6], s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %cmpxchg = cmpxchg i64 addrspace(1)* %cast.gep1, i64 %cmp, i64 %data seq_cst seq_cst
  %rtn = extractvalue { i64, i1 } %cmpxchg, 0
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @global_cmpxchg_saddr_i64_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %cmp, i64 %data) {
; GFX9-LABEL: global_cmpxchg_saddr_i64_nortn:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v6, v2
; GFX9-NEXT:    v_mov_b32_e32 v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v0, v[3:6], s[2:3]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_cmpxchg_saddr_i64_nortn:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v6, v2
; GFX10-NEXT:    v_mov_b32_e32 v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v0, v[3:6], s[2:3]
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_cmpxchg_saddr_i64_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v6, v2
; GFX11-NEXT:    v_mov_b32_e32 v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v0, v[3:6], s[2:3]
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %unused = cmpxchg i64 addrspace(1)* %cast.gep0, i64 %cmp, i64 %data seq_cst seq_cst
  ret void
}

define amdgpu_ps void @global_cmpxchg_saddr_i64_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %cmp, i64 %data) {
; GFX9-LABEL: global_cmpxchg_saddr_i64_nortn_neg128:
; GFX9:       ; %bb.0:
; GFX9-NEXT:    v_mov_b32_e32 v6, v2
; GFX9-NEXT:    v_mov_b32_e32 v5, v1
; GFX9-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX9-NEXT:    global_atomic_cmpswap_x2 v0, v[3:6], s[2:3] offset:-128
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    buffer_wbinvl1
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: global_cmpxchg_saddr_i64_nortn_neg128:
; GFX10:       ; %bb.0:
; GFX10-NEXT:    v_mov_b32_e32 v6, v2
; GFX10-NEXT:    v_mov_b32_e32 v5, v1
; GFX10-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    global_atomic_cmpswap_x2 v0, v[3:6], s[2:3] offset:-128
; GFX10-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX10-NEXT:    buffer_gl0_inv
; GFX10-NEXT:    buffer_gl1_inv
; GFX10-NEXT:    s_endpgm
;
; GFX11-LABEL: global_cmpxchg_saddr_i64_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    v_mov_b32_e32 v6, v2
; GFX11-NEXT:    v_mov_b32_e32 v5, v1
; GFX11-NEXT:    s_waitcnt vmcnt(0) lgkmcnt(0)
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    global_atomic_cmpswap_b64 v0, v[3:6], s[2:3] offset:-128
; GFX11-NEXT:    s_waitcnt_vscnt null, 0x0
; GFX11-NEXT:    buffer_gl0_inv
; GFX11-NEXT:    buffer_gl1_inv
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %unused = cmpxchg i64 addrspace(1)* %cast.gep1, i64 %cmp, i64 %data seq_cst seq_cst
  ret void
}

; --------------------------------------------------------------------------------
; amdgcn atomic inc
; --------------------------------------------------------------------------------

declare i32 @llvm.amdgcn.atomic.inc.i32.p1i32(i32 addrspace(1)* nocapture, i32, i32 immarg, i32 immarg, i1 immarg) #0
declare i64 @llvm.amdgcn.atomic.inc.i64.p1i64(i64 addrspace(1)* nocapture, i64, i32 immarg, i32 immarg, i1 immarg) #0

define amdgpu_ps float @global_inc_saddr_i32_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GCN-LABEL: global_inc_saddr_i32_rtn:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_inc v0, v0, v1, s[2:3] glc
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_inc_saddr_i32_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_inc_u32 v0, v0, v1, s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %rtn = call i32 @llvm.amdgcn.atomic.inc.i32.p1i32(i32 addrspace(1)* %cast.gep0, i32 %data, i32 0, i32 0, i1 false)
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @global_inc_saddr_i32_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GCN-LABEL: global_inc_saddr_i32_rtn_neg128:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_inc v0, v0, v1, s[2:3] offset:-128 glc
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_inc_saddr_i32_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_inc_u32 v0, v0, v1, s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %rtn = call i32 @llvm.amdgcn.atomic.inc.i32.p1i32(i32 addrspace(1)* %cast.gep1, i32 %data, i32 0, i32 0, i1 false)
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @global_inc_saddr_i32_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GCN-LABEL: global_inc_saddr_i32_nortn:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_inc v0, v1, s[2:3]
; GCN-NEXT:    s_endpgm
;
; GFX11-LABEL: global_inc_saddr_i32_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_inc_u32 v0, v1, s[2:3]
; GFX11-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %unused = call i32 @llvm.amdgcn.atomic.inc.i32.p1i32(i32 addrspace(1)* %cast.gep0, i32 %data, i32 0, i32 0, i1 false)
  ret void
}

define amdgpu_ps void @global_inc_saddr_i32_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GCN-LABEL: global_inc_saddr_i32_nortn_neg128:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_inc v0, v1, s[2:3] offset:-128
; GCN-NEXT:    s_endpgm
;
; GFX11-LABEL: global_inc_saddr_i32_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_inc_u32 v0, v1, s[2:3] offset:-128
; GFX11-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %unused = call i32 @llvm.amdgcn.atomic.inc.i32.p1i32(i32 addrspace(1)* %cast.gep1, i32 %data, i32 0, i32 0, i1 false)
  ret void
}

define amdgpu_ps <2 x float> @global_inc_saddr_i64_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GCN-LABEL: global_inc_saddr_i64_rtn:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_inc_x2 v[0:1], v0, v[1:2], s[2:3] glc
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_inc_saddr_i64_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_inc_u64 v[0:1], v0, v[1:2], s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %rtn = call i64 @llvm.amdgcn.atomic.inc.i64.p1i64(i64 addrspace(1)* %cast.gep0, i64 %data, i32 0, i32 0, i1 false)
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @global_inc_saddr_i64_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GCN-LABEL: global_inc_saddr_i64_rtn_neg128:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_inc_x2 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_inc_saddr_i64_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_inc_u64 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %rtn = call i64 @llvm.amdgcn.atomic.inc.i64.p1i64(i64 addrspace(1)* %cast.gep1, i64 %data, i32 0, i32 0, i1 false)
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @global_inc_saddr_i64_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GCN-LABEL: global_inc_saddr_i64_nortn:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_inc_x2 v0, v[1:2], s[2:3]
; GCN-NEXT:    s_endpgm
;
; GFX11-LABEL: global_inc_saddr_i64_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_inc_u64 v0, v[1:2], s[2:3]
; GFX11-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %unused = call i64 @llvm.amdgcn.atomic.inc.i64.p1i64(i64 addrspace(1)* %cast.gep0, i64 %data, i32 0, i32 0, i1 false)
  ret void
}

define amdgpu_ps void @global_inc_saddr_i64_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GCN-LABEL: global_inc_saddr_i64_nortn_neg128:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_inc_x2 v0, v[1:2], s[2:3] offset:-128
; GCN-NEXT:    s_endpgm
;
; GFX11-LABEL: global_inc_saddr_i64_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_inc_u64 v0, v[1:2], s[2:3] offset:-128
; GFX11-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %unused = call i64 @llvm.amdgcn.atomic.inc.i64.p1i64(i64 addrspace(1)* %cast.gep1, i64 %data, i32 0, i32 0, i1 false)
  ret void
}

; --------------------------------------------------------------------------------
; amdgcn atomic dec
; --------------------------------------------------------------------------------

declare i32 @llvm.amdgcn.atomic.dec.i32.p1i32(i32 addrspace(1)* nocapture, i32, i32 immarg, i32 immarg, i1 immarg) #0
declare i64 @llvm.amdgcn.atomic.dec.i64.p1i64(i64 addrspace(1)* nocapture, i64, i32 immarg, i32 immarg, i1 immarg) #0

define amdgpu_ps float @global_dec_saddr_i32_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GCN-LABEL: global_dec_saddr_i32_rtn:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_dec v0, v0, v1, s[2:3] glc
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_dec_saddr_i32_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_dec_u32 v0, v0, v1, s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %rtn = call i32 @llvm.amdgcn.atomic.dec.i32.p1i32(i32 addrspace(1)* %cast.gep0, i32 %data, i32 0, i32 0, i1 false)
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps float @global_dec_saddr_i32_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GCN-LABEL: global_dec_saddr_i32_rtn_neg128:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_dec v0, v0, v1, s[2:3] offset:-128 glc
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_dec_saddr_i32_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_dec_u32 v0, v0, v1, s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %rtn = call i32 @llvm.amdgcn.atomic.dec.i32.p1i32(i32 addrspace(1)* %cast.gep1, i32 %data, i32 0, i32 0, i1 false)
  %cast.rtn = bitcast i32 %rtn to float
  ret float %cast.rtn
}

define amdgpu_ps void @global_dec_saddr_i32_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GCN-LABEL: global_dec_saddr_i32_nortn:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_dec v0, v1, s[2:3]
; GCN-NEXT:    s_endpgm
;
; GFX11-LABEL: global_dec_saddr_i32_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_dec_u32 v0, v1, s[2:3]
; GFX11-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i32 addrspace(1)*
  %unused = call i32 @llvm.amdgcn.atomic.dec.i32.p1i32(i32 addrspace(1)* %cast.gep0, i32 %data, i32 0, i32 0, i1 false)
  ret void
}

define amdgpu_ps void @global_dec_saddr_i32_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i32 %data) {
; GCN-LABEL: global_dec_saddr_i32_nortn_neg128:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_dec v0, v1, s[2:3] offset:-128
; GCN-NEXT:    s_endpgm
;
; GFX11-LABEL: global_dec_saddr_i32_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_dec_u32 v0, v1, s[2:3] offset:-128
; GFX11-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i32 addrspace(1)*
  %unused = call i32 @llvm.amdgcn.atomic.dec.i32.p1i32(i32 addrspace(1)* %cast.gep1, i32 %data, i32 0, i32 0, i1 false)
  ret void
}

define amdgpu_ps <2 x float> @global_dec_saddr_i64_rtn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GCN-LABEL: global_dec_saddr_i64_rtn:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_dec_x2 v[0:1], v0, v[1:2], s[2:3] glc
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_dec_saddr_i64_rtn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_dec_u64 v[0:1], v0, v[1:2], s[2:3] glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %rtn = call i64 @llvm.amdgcn.atomic.dec.i64.p1i64(i64 addrspace(1)* %cast.gep0, i64 %data, i32 0, i32 0, i1 false)
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps <2 x float> @global_dec_saddr_i64_rtn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GCN-LABEL: global_dec_saddr_i64_rtn_neg128:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_dec_x2 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GCN-NEXT:    s_waitcnt vmcnt(0)
; GCN-NEXT:    ; return to shader part epilog
;
; GFX11-LABEL: global_dec_saddr_i64_rtn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_dec_u64 v[0:1], v0, v[1:2], s[2:3] offset:-128 glc
; GFX11-NEXT:    s_waitcnt vmcnt(0)
; GFX11-NEXT:    ; return to shader part epilog
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %rtn = call i64 @llvm.amdgcn.atomic.dec.i64.p1i64(i64 addrspace(1)* %cast.gep1, i64 %data, i32 0, i32 0, i1 false)
  %cast.rtn = bitcast i64 %rtn to <2 x float>
  ret <2 x float> %cast.rtn
}

define amdgpu_ps void @global_dec_saddr_i64_nortn(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GCN-LABEL: global_dec_saddr_i64_nortn:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_dec_x2 v0, v[1:2], s[2:3]
; GCN-NEXT:    s_endpgm
;
; GFX11-LABEL: global_dec_saddr_i64_nortn:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_dec_u64 v0, v[1:2], s[2:3]
; GFX11-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %cast.gep0 = bitcast i8 addrspace(1)* %gep0 to i64 addrspace(1)*
  %unused = call i64 @llvm.amdgcn.atomic.dec.i64.p1i64(i64 addrspace(1)* %cast.gep0, i64 %data, i32 0, i32 0, i1 false)
  ret void
}

define amdgpu_ps void @global_dec_saddr_i64_nortn_neg128(i8 addrspace(1)* inreg %sbase, i32 %voffset, i64 %data) {
; GCN-LABEL: global_dec_saddr_i64_nortn_neg128:
; GCN:       ; %bb.0:
; GCN-NEXT:    global_atomic_dec_x2 v0, v[1:2], s[2:3] offset:-128
; GCN-NEXT:    s_endpgm
;
; GFX11-LABEL: global_dec_saddr_i64_nortn_neg128:
; GFX11:       ; %bb.0:
; GFX11-NEXT:    global_atomic_dec_u64 v0, v[1:2], s[2:3] offset:-128
; GFX11-NEXT:    s_sendmsg sendmsg(MSG_DEALLOC_VGPRS)
; GFX11-NEXT:    s_endpgm
  %zext.offset = zext i32 %voffset to i64
  %gep0 = getelementptr inbounds i8, i8 addrspace(1)* %sbase, i64 %zext.offset
  %gep1 = getelementptr inbounds i8, i8 addrspace(1)* %gep0, i64 -128
  %cast.gep1 = bitcast i8 addrspace(1)* %gep1 to i64 addrspace(1)*
  %unused = call i64 @llvm.amdgcn.atomic.dec.i64.p1i64(i64 addrspace(1)* %cast.gep1, i64 %data, i32 0, i32 0, i1 false)
  ret void
}

attributes #0 = { argmemonly nounwind willreturn }
